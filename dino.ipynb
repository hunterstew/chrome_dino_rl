{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5118b0e0-9800-40b5-bcc9-23bf1268b1d1",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c28830-dcf1-444e-80e5-ee49211008a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# installs\n",
    "!pip3 install torch torchvision torchaudio\n",
    "!pip3 install 'stable-baselines3[extra]' protobuf==3.20.\\*\n",
    "!pip3 install mss pyautogui pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7937a1aa-3433-451e-97cc-e31dba63b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from mss import mss\n",
    "import pyautogui\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from gym import Env\n",
    "from gym.spaces import Box, Discrete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea57751-2b3b-401f-b7a5-fe08b4553532",
   "metadata": {},
   "source": [
    "# Game Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4348722c-b4ea-4d19-9451-58628636e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebGame(Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Setup spaces\n",
    "        self.observation_space = Box(low=0, high=255, shape=(1,60,150), dtype=np.uint8)\n",
    "        self.action_space = Discrete(3)\n",
    "        # Capture game frames\n",
    "        self.cap = mss()\n",
    "        # match to your window size\n",
    "        self.game_location = {'top': 400, 'left': 0, 'width': 1400, 'height': 220}\n",
    "        self.done_location = {'top': 405, 'left': 430, 'width': 660, 'height': 70}\n",
    "        # store game over image here...will show how later\n",
    "        self.template = cv2.imread('gameover.png',0)\n",
    "\n",
    "        \n",
    "        \n",
    "    def step(self, action):\n",
    "        action_map = {\n",
    "            0:'space',\n",
    "            1: 'down', \n",
    "            2: 'no_op'\n",
    "        }\n",
    "        if action !=2:\n",
    "            pyautogui.press(action_map[action])\n",
    "\n",
    "        done, done_cap = self.get_done() \n",
    "        observation = self.get_observation()\n",
    "        if done:\n",
    "            reward = -20\n",
    "        else:\n",
    "            reward = 1\n",
    "        info = {}\n",
    "        return observation, reward, done, info\n",
    "        \n",
    "    \n",
    "    def reset(self):\n",
    "        time.sleep(1)\n",
    "        pyautogui.click(150, 150)\n",
    "        pyautogui.press('space')\n",
    "        return self.get_observation()\n",
    "        \n",
    "    def render(self):\n",
    "        cv2.imshow('Game', self.current_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            self.close()\n",
    "         \n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    def get_observation(self):\n",
    "        raw = np.array(self.cap.grab(self.game_location))[:,:,:3].astype(np.uint8)\n",
    "        gray = cv2.cvtColor(raw, cv2.COLOR_BGR2GRAY)\n",
    "        resized = cv2.resize(gray, (150,60))\n",
    "        channel = np.reshape(resized, (1,60,150))\n",
    "        return channel\n",
    "    \n",
    "    def get_done(self):\n",
    "        done_cap = np.array(self.cap.grab(self.done_location))\n",
    "        img = cv2.cvtColor(done_cap[:,:,:3], cv2.COLOR_RGB2GRAY)\n",
    "        #plt.imshow(img)\n",
    "        #plt.imshow(self.template)\n",
    "        # on first run, uncomment so it saves 'game over' image, then comment out again\n",
    "        # adjust path to your machine\n",
    "        #cv2.imwrite('/Users/hunterstew/gameover.png', img)\n",
    "\n",
    "        done = False\n",
    "        res = cv2.matchTemplate(img,self.template,cv2.TM_CCOEFF_NORMED)[0][0]\n",
    "        if res > .99:\n",
    "            done = True\n",
    "        return done, done_cap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec4706b-6147-4b65-a109-38eb1f6d6c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test code to make sure its working\n",
    "env = WebGame()\n",
    "obs=env.get_observation()\n",
    "#UNCOMMENT AND ADJUST self.game_location/done_location to your screen size\n",
    "#plt.imshow(cv2.cvtColor(obs[0], cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "done, done_cap = env.get_done()\n",
    "print(done)\n",
    "\n",
    "for episode in range(1): \n",
    "    obs = env.reset()\n",
    "    done = False  \n",
    "    total_reward   = 0\n",
    "    while not done: \n",
    "        obs, reward,  done, info =  env.step(env.action_space.sample())\n",
    "        total_reward  +=    reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode, total_reward))       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49008549-2bfd-4905-a9c4-a3ca9af1e5bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Helpers for saving trained models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fbb344-1bf4-4998-bd61-8a334126854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os for file path management\n",
    "import os \n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "# Check Environment    \n",
    "from stable_baselines3.common import env_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce6093b-eb6b-4f91-b182-1ed5081392ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bba1f70-d846-4d8a-8007-073b8a7b996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451894bc-c73d-4bd8-b3a7-bea3bdacc2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './trainv9/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a1dfbb-7956-4b71-ad34-0b1426cfb692",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=1000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e7f8ad-3fc2-45ac-9083-840578ebdc07",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0cbabc-500f-4a11-8a81-17e620ae9fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c108cbb-c12e-4c01-ba79-adf358fb0954",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WebGame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0a2b9c-8fa0-4c0c-8b01-e825df0835ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = DQN('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, buffer_size=1200000, learning_starts=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf25f0-114d-41c8-b284-46aa546325f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=1000000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8ae8e8-2858-41c9-95be-91e5d78d0e60",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05435901-ec72-481d-b538-cb1b1ea7bf4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = DQN.load('/Users/hunterstew/trainv8/best_model_325000.zip', env=env, print_system_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44f387c-5eef-4d14-9183-468b53652bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for episode in range(5): \n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(int(action))\n",
    "        #plt.imshow(cv2.cvtColor(obs[0], cv2.COLOR_GRAY2BGR))\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode, total_reward))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
